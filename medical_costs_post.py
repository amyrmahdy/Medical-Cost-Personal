# -*- coding: utf-8 -*-
"""medical_costs_post.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zeZ0mJG9c9WZ_l32tF0g5q6X6x6bbwJy

# Get the Data
"""

import numpy as np
import pandas as pd
import seaborn as sns
from scipy.stats import randint
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.pipeline import make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV

medical = pd.read_csv("https://bit.ly/44evDuW")

"""# Take a Quick Look at the Data Structure"""

medical.head()

medical.info()

medical.region.value_counts()

medical.describe()

medical.hist()
plt.show()

# age, children and charges are positively skewed
# bmi is normal

"""## Create a Test Set"""

RS = 13

X = medical.drop(["charges"], axis = 1)
y = medical[["charges"]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = RS)

"""# Explore and Visualize the Data to Gain Insights"""

X_train

train = X_train.copy()
train["charges"] = y_train.copy()

train["charges"].hist()
plt.show()

pd.DataFrame(np.log10(train.charges)).hist()
plt.show()

"""Now let's look at the mean charges by region"""

train[["region","charges"]].groupby(["region"]).mean()

sns.catplot(data = train, x = "region", y = "charges", hue = "sex", kind = "bar")
plt.show()

# males charges are more than females (in 3/4 cases)
# southwest has the lowest charges for females
# northwest has the lowest charges for males
# southeast has the highest charges for both

sns.catplot(data = train, x = "region", y = "charges", hue = "smoker", kind = "bar")
plt.show()

# smokers has 3 times more charges than non-smokers
# north east has the highest charges for non-smokers, but the lowest charges for smokers

sns.catplot(data = train, x = "region", y = "charges", hue = "children", kind = "bar")
plt.show()

# in southwest family with 2 children has the highest charge and with 5 childern hast the lowest charge
# in southeast family with 3 children has the highest charge and with 5 children hast the lowest charge
# in northwest family with 3 children hast the highest charge and with 1 child has the lowest charge
# in northeast family with 1 child has the highest charge and with 5 children has the lowest charge

sns.lmplot(data = train,x = "age", y = "charges", hue = "smoker",)
plt.show()

# age and smoking both positively effect on charges

sns.lmplot(data = train,x = "bmi", y = "charges", hue = "smoker",)
plt.show()

# smoking highly effect on charges
# bmi effect on charges, but needs more clear plot for analyze

sns.lmplot(data = train,x = "children", y = "charges", hue = "smoker",)
plt.show()

# outliers of charges are mostly smokers and have less than 4 children

"""### Look for Correlations"""

train.corr()

pd.plotting.scatter_matrix(train)
plt.show()

train.plot(kind = 'scatter', x = "bmi", y = 'charges', alpha = 0.3)
plt.show()

"""# Transformation Pipelines"""

num_attribs = ["age", "bmi", "children"]
cat_attribs = ["sex", "smoker", "region"]

num_pipeline = make_pipeline(
    SimpleImputer(strategy="median"),
    StandardScaler())

cat_pipeline = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore", drop = 'first'))

preprocessing = ColumnTransformer([
    ("num", num_pipeline, num_attribs),
    ("cat", cat_pipeline, cat_attribs)])

X_train_perpared = preprocessing.fit_transform(X_train)

print(X_train_perpared.shape)
print(preprocessing.get_feature_names_out())

"""# Select and Train a Model

## Train and Evaluate on the Training Set

"""

lin_reg = Pipeline([
    ("preprocessing", preprocessing),
    ("linear_regression",LinearRegression())
])

lin_reg.fit(X_train, y_train)

y_predictions_lin = lin_reg.predict(X_test)
y_predictions_lin[:5]

lin_rmse = mean_squared_error(y_test, y_predictions_lin, squared=False)
lin_rmse

dt_reg = Pipeline([
    ("preprocessing", preprocessing),
    ("decision_tree",DecisionTreeRegressor(random_state=RS))
])

dt_reg.fit(X_train, y_train)

y_predictions_dt = dt_reg.predict(X_test)
y_predictions_dt[:5]

dt_rmse = mean_squared_error(y_test, y_predictions_dt, squared=False)
dt_rmse

"""# Better Evaluation Using Cross-Validation

"""

tree_pipeline = Pipeline([
    ("preprocessing",preprocessing),
    ("tree", DecisionTreeRegressor(random_state = RS))
])

tree_rmses = cross_val_score(tree_pipeline,
                              X_train, y_train,
                              scoring="neg_root_mean_squared_error",
                              cv=10)
tree_rmses

np.mean(tree_rmses * -1)

np.median(tree_rmses * -1)

rfr_reg = Pipeline([
    ("preprocessing",preprocessing),
    ("random_forest",RandomForestRegressor(random_state=RS))
])
rfr_reg.fit(X_train, y_train)

y_predictions_rfr = rfr_reg.predict(X_test)
y_predictions_rfr[:5]

rfr_rmse = mean_squared_error(y_test, y_predictions_rfr, squared=False)
rfr_rmse

"""# Fine-Tune Your Model

## Randomized Search for Good Hyperparameters
"""

full_pipeline = Pipeline([("preprocessing", preprocessing),
                          ("random_forest", RandomForestRegressor(random_state=RS))
                          ])

param_distribs = {'random_forest__max_features': randint(low=2,high=20)}

rnd_search = RandomizedSearchCV(full_pipeline,
                                param_distributions=param_distribs,
                                n_iter=10,
                                cv=3,
                                scoring='neg_root_mean_squared_error',
                                random_state=RS)
rnd_search.fit(X_train, y_train)

rn_res = pd.DataFrame(rnd_search.cv_results_)
rn_res.sort_values(by="mean_test_score", ascending=False, inplace=True)
rn_res.head(5)["mean_test_score"]

final_model = rnd_search.best_estimator_ # includes preprocessing
feature_importances = final_model["random_forest"].feature_importances_
feature_importances

sorted(zip(feature_importances, final_model["preprocessing"].get_feature_names_out()),reverse=True)

final_rfr_reg = Pipeline([
    ("preprocessing", preprocessing),
    ("final_random_forest", RandomForestRegressor(random_state=RS, max_features = 4))
])

final_rfr_reg.fit(X_train, y_train)

y_predictions_final_rfr = final_rfr_reg.predict(X_test)
y_predictions_final_rfr[:5]

final_rfr_rmse = mean_squared_error(y_test, y_predictions_final_rfr, squared=False)
final_rfr_rmse